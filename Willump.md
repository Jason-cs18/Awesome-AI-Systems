# Willump: A Statistically-Aware End-to-end Optimizer for Machine Learning Inference. In MLSys'20.
## Problem
When machine learning (ML) researchers optimize the inference workloads over tabular data, they often treat ML models as black boxes and implement systems optimizations. But they ignore the potential from statistical characteristics of ML in inference.
## Solution
They proposed Willump, an end2end optimizer for machine learning inference pipelines built on two novel optimizations: cascade feature computations and approximating top-K queries. _Figure 2_ shows the architecture of Willump.
![](https://github.com/YanLu-nyu/Awesome-AI-Systems/blob/master/willump_arch.png)<br>
To construct these components, they created and trained **an approximate model** to assign the difficulties to all data (how to construct this model is very interesting to me). Based on their different difficulties, they choose the corresponding feature computation pipelines. Beside their difficulties, we also got coarse scores from the approximate model. Using these scores, they filtered out low-scoring data and used model based on all features to generate accurate scores for remaining data (high-scoring data generated by the approximate model).
## Evaluation
Query throughput and latency.
## Contribution
In summary, there are three contributions in this work: 1) a statistically-aware end2end optimizer for ML inference pipelines; 2) automatically cascading feature computation through **an approximate model**; 3) automatically approximating top-K queries by filtering out low-scoring candidates generated by the approximate model.
## Key insight
Combining feature about input's difficulty can accelerate ML inference pipelines without significant accuracy loss in traditional machine learning inference over tabular data. 
## Limitation
Like ML inference pipelines, deep learning inference engines take much time on feature extraction. 
But the deep features are hard to interpret and be selected as the feature group for an approximate model. 
Besides, constructing approximate models based on deep features consumes more time than ML features. 
Thus, scaling Willump to **deep learning algorithms** may be more challenging.
