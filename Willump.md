# Willump: A Statistically-Aware End-to-end Optimizer for Machine Learning Inference. In MLSys'20.
## Problem
## Solution
## Evaluation
Query throughput and latency.
## Contribution
## Key insight
## Limitation
Like ML inference pipelines, deep learning inference engines take much time on feature extraction. 
But the deep features are hard to interpret and be selected as the feature group for an approximate model. 
Besides, constructing approximate models based on deep features consumes more time than ML features. 
Thus, scaling Willump to deep learning algorithms may be more challenging.
